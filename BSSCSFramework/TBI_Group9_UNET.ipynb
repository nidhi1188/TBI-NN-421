{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TBI-Group9-UNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3tpRHd5-41Cu",
        "colab_type": "code",
        "outputId": "73083e27-5cc6-4236-d5d5-c6eb38b26331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!pip install pillow\n",
        "import json\n",
        "import pandas as pd\n",
        "import tqdm as tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm as tqdm\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (3.0.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (4.1.1)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1vupi9GeVq0H",
        "colab_type": "code",
        "outputId": "2d4c102c-28b2-46af-8bcb-ed847fd2083f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        }
      },
      "cell_type": "code",
      "source": [
        "api_token = {\"username\":\"twoface262\",\"key\":\"453e89deca1ef616f15f5725eed93000\"}\n",
        "\n",
        "with open('kaggle.json', 'w') as kaggle_json:\n",
        "  json.dump(api_token, kaggle_json)\n",
        "  \n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Dataset source: https://www.kaggle.com/nikhilpandey360/chest-xray-masks-and-labels\n",
        "# Attributes: Jaeger S, Karargyris A, Candemir S, Folio L, Siegelman J, Callaghan F, Xue Z, Palaniappan K, Singh RK, Antani S, Thoma G, Wang YX, Lu PX, McDonald CJ. Automatic tuberculosis screening using chest radiographs. IEEE Trans Med Imaging. 2014 Feb;33(2):233-45. doi: 10.1109/TMI.2013.2284099. PMID: 24108713 Candemir S, Jaeger S, Palaniappan K, Musco JP, Singh RK, Xue Z, Karargyris A, Antani S, Thoma G, McDonald CJ. Lung segmentation in chest radiographs using anatomical atlases with nonrigid registration. IEEE Trans Med Imaging. 2014 Feb;33(2):577-90. doi: 10.1109/TMI.2013.2290491. PMID: 24239990 Montgomery County X-ray Set X-ray images in this data set have been acquired from the tuberculosis control program of the Department of Health and Human Services of Montgomery County, MD, USA. This set contains 138 posterior-anterior x-rays, of which 80 x-rays are normal and 58 x-rays are abnormal with manifestations of tuberculosis. All images are de-identified and available in DICOM format. The set covers a wide range of abnormalities, including effusions and miliary patterns. The data set includes radiology readings available as a text file.\n",
        "!kaggle datasets download nikhilpandey360/chest-xray-masks-and-labels\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading chest-xray-masks-and-labels.zip to /content\n",
            "100% 4.79G/4.79G [01:45<00:00, 66.0MB/s]\n",
            "100% 4.79G/4.79G [01:45<00:00, 48.9MB/s]\n",
            "chest-xray-masks-and-labels.zip  kaggle.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x26mSbiN8CMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data_train\n",
        "!unzip chest-xray-masks-and-labels.zip -d data_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRayhjX2_fbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls data_train/Lung\\ Segmentation/ClinicalReadings\n",
        "\n",
        "file_x = open(\"data_train/Lung Segmentation/ClinicalReadings/CHNCXR_0613_1.txt\")\n",
        "print(file_x.read())\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vTjDf0AEDsvR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have to base the label off of the name. 0 indicates normal and 1 indicates PTB.\n",
        "\n",
        "We should first load in the iamges and label them. We can label them as 0 for normal and 1 for PTB (single labeled, but will be fine)"
      ]
    },
    {
      "metadata": {
        "id": "FmIa8P9r2yL6",
        "colab_type": "code",
        "outputId": "1d938bfb-27dd-4318-d66e-3dfcc0b48592",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "cell_type": "code",
      "source": [
        "!ls data_train/Lung\\ Segmentation"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ClinicalReadings  masks\t\t\t       NLM-MontgomeryCXRSet-ReadMe.pdf\n",
            "CXR_png\t\t  NLM-ChinaCXRSet-ReadMe.docx  test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LZtcBLmZ_eyk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Authors: Wezley Sherman\n",
        "#\n",
        "# Reference Attributes: Pydicom documentation, glob documentation\n",
        "# https://pydicom.github.io/pydicom/stable/getting_started.html\n",
        "# https://pymotw.com/2/glob/\n",
        "#\n",
        "# This class is a part of the BSSCS Net Framework to import DICOM images\n",
        "#\n",
        "# BSSCS Docs Importer location: BSSCS_DOCS/dicom.html\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "import os\n",
        "\n",
        "class UNET_DATA:\n",
        "  def __init__(self,label_classes, batch_size=5, labels_arr=None, image_arr=None, csv_path=None, images_path=None):\n",
        "    self.current_batch = 0\n",
        "    self.batch_size = batch_size\n",
        "    self.total_batches = 5\n",
        "    self.batch_size = batch_size\n",
        "    self.labels = labels_arr\n",
        "    self.images = image_arr\n",
        "    self.label_classes = label_classes\n",
        "    self.images_path = images_path\n",
        "\n",
        "    if csv_path and images_path:\n",
        "      print(\"Found CSV\")\n",
        "      data_frame = self.open_csv(csv_path)\n",
        "      self.data_dictionary = self.fetch_images_with_csv(images_path, data_frame)\n",
        "      self.data_keys = list(self.data_dictionary.keys())\n",
        "    else:\n",
        "      print(\"No CSV\")\n",
        "      self.data_dictionary = None\n",
        "\n",
        "  def set_batch_size(self, new_size):\n",
        "    ''' Responsible for setting a new batch size\n",
        "\n",
        "    Input:\n",
        "    - new_size: int -- corresponds to the new batch size we want to assign\n",
        "    '''\n",
        "    self.batch_size = new_size\n",
        "\n",
        "  def get_batch_size(self):\n",
        "    ''' Responsible for returning the batch size for the class\n",
        "\n",
        "    Returns:\n",
        "    -int -- corresponds to the batch size\n",
        "    '''\n",
        "    return self.batch_size\n",
        "\n",
        "  def get_total_batches(self):\n",
        "    ''' Responsible for returning how many batches of data are in our dataset\n",
        "\n",
        "    Returns:\n",
        "    - int -- corresponds to the number of batches in our dataset\n",
        "    '''\n",
        "    return math.floor(self.images/batch_size)\n",
        "\n",
        "\n",
        "  def get_next_batch(self):\n",
        "    '''\tResponsible for batching the data arrays and returning them\n",
        "\n",
        "    Returns: \n",
        "    label_batch: arr -- batch of labels for the associated image\n",
        "    image_batch: arr -- batch of images for the associated labels\n",
        "    '''\n",
        "    start_pos = (self.current_batch)\n",
        "    end_pos =  (self.current_batch+1)\n",
        "    print(\"Called start\", start_pos)\n",
        "    print(\"end \", end_pos)\n",
        "    label_batch = []\n",
        "    image_batch = []\n",
        "    if not self.data_dictionary:\n",
        "      label_batch = self.labels[start_pos:end_pos]\n",
        "      image_batch = self.images[start_pos:end_pos]\n",
        "    else:\n",
        "      label_batch_keys = self.data_keys[start_pos:end_pos]\n",
        "    for key in label_batch_keys:\n",
        "      print(\"keys \", key)        \n",
        "      image_batch.append(np.resize(np.array(self.data_dictionary[key]['image_arr']), (256, 256, 1)))\n",
        "      label_batch.append(self.data_dictionary[key]['labels'])\n",
        "\n",
        "    # Reset the current batch once we've iterated through all of our data\n",
        "    self.current_batch += 1\n",
        "    if(self.current_batch >= self.batch_size):\n",
        "      self.current_batch = 0\n",
        "\n",
        "    return label_batch, image_batch\n",
        "  \n",
        "  def get_batch_from_dir(self):\n",
        "    start_pos = (self.current_batch)\n",
        "    end_pos = (self.current_batch+self.batch_size)\n",
        "    batch_data = []\n",
        "    \n",
        "    for obj in list(self.data_dictionary.items())[start_pos: end_pos]:\n",
        "      mask = obj[1]['mask']\n",
        "      truth = obj[1]['truth']\n",
        "      label = obj[1]['label']\n",
        "      batch_data.append([mask, truth, label])\n",
        "    \n",
        "    # Reset the current batch once we've iterated through all of our data\n",
        "    self.current_batch += 1\n",
        "    if(self.current_batch >= self.batch_size):\n",
        "      self.current_batch = 0\n",
        "\n",
        "    return batch_data\n",
        "  \n",
        "  def fetch_data(self, path_to_csv):\n",
        "    ''' Handles fetching the data from the DICOM Importer\n",
        "\n",
        "    Assigns:\n",
        "    self.labels\n",
        "    self.images\n",
        "    '''\n",
        "    images_arr, labels_arr = self.import_labels_from_csv(path_to_csv)\n",
        "    self.images = images_arr\n",
        "    self.labels = labels_arr\n",
        "\n",
        "  def import_labels_from_csv(self, path):\n",
        "    ''' Handles opening a CSV of data and reading in the information to match\n",
        "    The image with the label.\n",
        "\n",
        "    Input: \n",
        "    - path: String -- path to the CSV\n",
        "\n",
        "    Returns:\n",
        "    - images: list -- list of image file names\n",
        "    - labels: list -- list of boolean labels\n",
        "    '''\n",
        "    csv_dataframe = pd.read_csv(path)\n",
        "    images = list(csv_dataframe['file_name'])\n",
        "    labels = list(csv_dataframe['has_tbi'])\n",
        "    return images, labels\n",
        "\n",
        "  def open_csv(self, path):\n",
        "    ''' Handles opening a labels CSV for the test set and returning the datframe\n",
        "\n",
        "    Input:\n",
        "    - path: String -- path to CSV\n",
        "\n",
        "    Returns:\n",
        "    - csv_dataframe: pandas dataframe for labels\n",
        "\n",
        "    '''\n",
        "    csv_dataframe = pd.read_csv(path)\n",
        "    return csv_dataframe\n",
        "\n",
        "  def scale_image(self, image, width, height):\n",
        "    ''' Handles scaling an image so that it can be fed into the UNET.\n",
        "\n",
        "    Input:\n",
        "    - image: A PIL Image instance\n",
        "    - width: the new width we want the image to be\n",
        "    - height: the new height we want the image to be\n",
        "\n",
        "    Returns:\n",
        "    - A PIL image instance that has been scaled\n",
        "\n",
        "    * Will apply antialiasing to the \n",
        "    '''\n",
        "    return image.resize((width, height), Image.ANTIALIAS)\n",
        "\n",
        "\n",
        "  def fetch_images_with_csv(self, path, dataframe):\n",
        "    ''' Handles fetching images from a filepath and constructs a dictionary with their labels\n",
        "\n",
        "    Input:\n",
        "    - path: String -- path to data folder\n",
        "    - dataframe: pandas dataframe\n",
        "\n",
        "    Returns:\n",
        "    - Dictionary of data structured as:\n",
        "    {\n",
        "      image_name : {\n",
        "        image_arr: [2D pixel array],\n",
        "        labels: [labels array]\n",
        "      }\n",
        "    }\n",
        "    '''\n",
        "    data_dictionary = {}\n",
        "    count = 0\n",
        "    for row in tqdm(dataframe.iterrows()):\n",
        "      data_dictionary[row[1][0]] = {}\n",
        "      image_path = path +'/' + row[1][0] + '_blue.png'\n",
        "      image = list(self.scale_image(Image.open(image_path), 256, 256).getdata())\n",
        "      data_dictionary[row[1][0]]['image_arr'] = image\n",
        "      label_classes_arr = np.zeros(shape=(28))\n",
        "      labels_in_data = np.array(row[1][1].split(' '))\n",
        "      print(self.label_classes)\n",
        "      print(labels_in_data)\n",
        "      for label in labels_in_data:\n",
        "        label_idx = int(label)\n",
        "        print(label_idx)\n",
        "        print(labels_in_data.size)\n",
        "        label_classes_arr[label_idx] = 1\n",
        "        print(label_classes_arr)\n",
        "        data_dictionary[row[1][0]]['labels'] = label_classes_arr\n",
        "      if count == self.batch_size:\n",
        "        break\n",
        "      count += 1\n",
        "    return data_dictionary\n",
        "\n",
        "  def fetch_images_and_masks_from_dir(self, mask_dir, label_dir, image_dir):\n",
        "    data_dictionary = {}\n",
        "    count = 0\n",
        "    mask_dir = self.images_path + \"/\" + mask_dir\n",
        "    for file in os.listdir(mask_dir):\n",
        "      mask = mask_dir + \"/\" + file\n",
        "      truth_image = self.images_path + \"/\" + image_dir + \"/\" + file.replace(\"_mask\", \"\") if \"CHNCXR\" in file else file\n",
        "      clinical_label = self.images_path + \"/\" + label_dir + \"/\" + file.replace(\"_mask.png\", \".txt\") if \"CHNCXR\" in file else file.replace(\".png\", \".txt\")\n",
        "     \n",
        "      if os.path.exists(truth_image) and os.path.exists(clinical_label):\n",
        "        label_file = open(clinical_label, \"r\")\n",
        "        data_dictionary[file] = {}\n",
        "        data_dictionary[file]['mask'] = list(self.scale_image(Image.open(mask), 256, 256).getdata())\n",
        "        data_dictionary[file]['label'] = label_file\n",
        "        data_dictionary[file]['truth'] = list(self.scale_image(Image.open(truth_image), 256, 256).getdata())\n",
        "        count += 1\n",
        "      else:\n",
        "        print(\"No match\")\n",
        "    \n",
        "      if count == self.batch_size:\n",
        "        break\n",
        "    return data_dictionary\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8EV4wcz57HcP",
        "colab_type": "code",
        "outputId": "ad4a10fc-8a1e-41a3-f096-fde86cab0cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "# test data fetch from fetch_images_and_masks_from_dir() method\n",
        "unet_data = UNET_DATA(label_classes=None, images_path=\"data_train/Lung Segmentation\")\n",
        "unet_data.data_dictionary = unet_data.fetch_images_and_masks_from_dir(\"masks\", \"ClinicalReadings\", \"CXR_png\")\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No CSV\n",
            "No match\n",
            "No match\n",
            "No match\n",
            "No match\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AKEbjChFU6ws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "unet_data.get_batch_from_dir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTMEK-5D_VmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Authors: Wezley Sherman\n",
        "#\n",
        "# Reference Attributes: U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
        "# Authors: Olaf Ronneberger, Philipp Fischer, and Thomas Brox\n",
        "#\n",
        "# This class is a part of the BSSCS Net Framework to import DICOM images and batch them for the UNET\n",
        "#\n",
        "# BSSCS Docs Importer location: TBD\n",
        "#\n",
        "# Citation:\n",
        "# Ronneberger, et al. “U-Net: Convolutional Networks for Biomedical Image Segmentation.” \n",
        "#     [Astro-Ph/0005112] A Determination of the Hubble Constant from Cepheid Distances and a Model of the Local Peculiar Velocity Field, \n",
        "#     American Physical Society, 18 May 2015, arxiv.org/abs/1505.04597.\n",
        "# Site:\n",
        "# https://arxiv.org/pdf/1505.04597.pdf\n",
        "import tensorflow as tf\n",
        "\n",
        "class BSSCS_UNET:\n",
        "  def __init__(self, iterations, batch_size, data_class, labels_shape=[None, 1], learning_rate=0.0001):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.iterations = iterations\n",
        "    self.batch_size = batch_size\n",
        "    self.data_class = data_class\n",
        "    self.labels_shape = labels_shape\n",
        "\n",
        "\n",
        "  def generate_unet_arch(self, input):\n",
        "    ''' Handles generating a TF Implementation of a UNET utilizing the architecture discussed in\n",
        "    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\" by Ronneberger, Fischer, and Brox\n",
        "\n",
        "    The architecture for the UNET is not ours and all accrediation goes to Olaf Ronneberger, Philipp Fischer, and Thomas Brox. \n",
        "    We are not claiming any ownership for the architecture. \n",
        "    Implementing the UNET arch is comparable to implementing selection sort.\n",
        "\n",
        "    tf.layers.conv2d docs: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d\n",
        "    tf.layers.conv2d_transpost for up convolutions: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d_transpose\n",
        "    tf.concat for the copy and crop methods: https://www.tensorflow.org/api_docs/python/tf/concat\n",
        "    tf.slice for cropping the tensors: https://www.tensorflow.org/api_docs/python/tf/slice\n",
        "    Hopefully I implemented this correctly  ¯\\_(ツ)_/¯\n",
        "\n",
        "    Quick guide on cropping a tensor -..\n",
        "\n",
        "    So after some research through the doc's I found out that we can't just crop it as if it were an image, because we are dealing with Tensors (matricies of data).\n",
        "\n",
        "    In order to crop a tensor we must use TensorFlow's slice function (https://www.tensorflow.org/api_docs/python/tf/slice)\n",
        "\n",
        "    Here we are cropping the convolutional layer we are upsampling to be the size of the convolutional layer we are concating to. \n",
        "    I'm starting at the base coordinates for the tensor object, and am cropping JUST the images (or filters). Thus why we have [-1, size_x, size_y, -1]. \n",
        "    The '-1' values are there to ensure we are keeping the remaining elements of the dimension (AKA our batch size and number of filters) . \n",
        "    From TF Docs on the -1 values: \" If size[i] is -1, all remaining elements in dimension i are included in the slice. In other words, this is equivalent to setting: size[i] = input.dim_size(i) - begin[i]\"\n",
        "\n",
        "    Once the tensor is properly cropped (Where each filter is the same size as the tensor we are copying into), we can concat the tensors. \n",
        "    This allows us to copy in all of the previous filters into the current tensor. The final shape will be: [Batch, Img_X, Img_Y, [Filters_A + Filters_B]]\n",
        "    '''\n",
        "    # first block in UNET --> Concat with the final block\n",
        "    convolution_layer_1 = tf.layers.conv2d(inputs=input, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_2 = tf.layers.conv2d(inputs=convolution_layer_1, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_1 = tf.layers.max_pooling2d(inputs=convolution_layer_2, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # second block in UNET --> Concat with second to final block\n",
        "    convolution_layer_3 = tf.layers.conv2d(inputs=max_pooling_layer_1, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_4 = tf.layers.conv2d(inputs=convolution_layer_3, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_2 = tf.layers.max_pooling2d(inputs=convolution_layer_4, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # third block in UNET --> Concat with third from final block\n",
        "    convolution_layer_5 = tf.layers.conv2d(inputs=max_pooling_layer_2, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_6 = tf.layers.conv2d(inputs=convolution_layer_5, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_3 = tf.layers.max_pooling2d(inputs=convolution_layer_6, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # fourth block in UNET --> Concat with fourth from final block\n",
        "    convolution_layer_7 = tf.layers.conv2d(inputs=max_pooling_layer_3, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_8 = tf.layers.conv2d(inputs=convolution_layer_7, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_4 = tf.layers.max_pooling2d(inputs=convolution_layer_8, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # middle UNET block\n",
        "    convolution_layer_9 = tf.layers.conv2d(inputs=max_pooling_layer_4, filters=1024, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_10 = tf.layers.conv2d(inputs=convolution_layer_9, filters=1024, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_1 = tf.layers.conv2d_transpose(inputs=convolution_layer_10, filters=1024, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "    # fourth from last \n",
        "    convolution_layer_8 = tf.slice(convolution_layer_8, [0, 0, 0, 0], [-1, convolution_up_1.shape[1], convolution_up_1.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_1, convolution_layer_8], axis=3) # Note: Experiment with the axis to ensure it is correct. Are we copying the batches or the filters? -- However; different axis's cause an error.\n",
        "    # print(concat_layer_1.shape) # Comes out to be [Batch_Size, Image_X, Image_Y, (Filters_Conv_8 + Filters_Conv_Up_1)]\n",
        "    convolution_layer_11 = tf.layers.conv2d(inputs=concat_layer_1, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_12 = tf.layers.conv2d(inputs=convolution_layer_11, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_2 = tf.layers.conv2d_transpose(inputs=convolution_layer_12, filters=512, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "\n",
        "    # third from last\n",
        "    convolution_layer_6 = tf.slice(convolution_layer_6, [0, 0, 0, 0], [-1, convolution_up_2.shape[1], convolution_up_2.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_2, convolution_layer_6], axis=3)\n",
        "    convolution_layer_13 = tf.layers.conv2d(inputs=convolution_up_2, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_14 = tf.layers.conv2d(inputs=convolution_layer_13, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_3 = tf.layers.conv2d_transpose(inputs=convolution_layer_14, filters=256, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "    # second from last\n",
        "    convolution_layer_4 = tf.slice(convolution_layer_4, [0, 0, 0, 0], [-1, convolution_up_3.shape[1], convolution_up_3.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_3, convolution_layer_4], axis=3)\n",
        "    convolution_layer_15 = tf.layers.conv2d(inputs=convolution_up_3, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_16 = tf.layers.conv2d(inputs=convolution_layer_15, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_4 = tf.layers.conv2d_transpose(inputs=convolution_layer_16, filters=128, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "    # last block\n",
        "    convolution_layer_2 = tf.slice(convolution_layer_2, [0, 0, 0, 0], [-1, convolution_up_4.shape[1], convolution_up_4.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_4, convolution_layer_2], axis=3)\n",
        "    convolution_layer_17 = tf.layers.conv2d(inputs=convolution_up_4, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_18 = tf.layers.conv2d(inputs=convolution_layer_17, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_19 = tf.layers.conv2d(inputs=convolution_layer_18, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_5 = tf.layers.conv2d_transpose(inputs=convolution_layer_19, filters=2, kernel_size=[1, 1], strides=1, padding=\"SAME\")\n",
        "    print(convolution_up_5.shape)\n",
        "    flattened = tf.reshape(convolution_up_5, [-1, 504])\n",
        "    return flattened\n",
        "\n",
        "  def create_regressor(self, input): \n",
        "    ''' Handles creating the regressor for the UNET classification\n",
        "\n",
        "        Parameters:\n",
        "          - input -- input layer (flattened layer from UNET) \n",
        "        Returns:\n",
        "          - Tensor -- last layer in the regressor\n",
        "    '''\n",
        "    reg_input = tf.layers.dense(inputs=input, units=504, activation=tf.nn.relu)\n",
        "    reg_hidden = tf.layers.dense(inputs=reg_input, units=800, activation=tf.nn.relu)\n",
        "    reg_hidden1 = tf.layers.dense(inputs=reg_hidden, units=1000, activation=tf.nn.relu)\n",
        "    reg_hidden2 = tf.layers.dense(inputs=reg_hidden1, units=1500, activation=tf.nn.relu)\n",
        "    reg_out = tf.layers.dense(inputs=reg_hidden2, units=28)\n",
        "    return reg_out\n",
        "\n",
        "  def create_loss(self, input, labels):\n",
        "    ''' Handles creating a loss function and returning it to the optimizer\n",
        "\n",
        "      Parameters:\n",
        "        - Input: The final layer in the graph we are computing the loss for\n",
        "        - Labels: The labels for the batch we are computing the loss for\n",
        "\n",
        "      Returns:\n",
        "        - Defined loss function\n",
        "\n",
        "      TensorFlow documentation: \n",
        "      https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2\n",
        "    '''\n",
        "    return tf.nn.softmax_cross_entropy_with_logits_v2(logits=input, labels=labels)\n",
        "\n",
        "  def create_optimizer(self, input, labels):\n",
        "    '''\n",
        "\n",
        "      TensorFlow documentation: \n",
        "      https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n",
        "    '''\n",
        "    loss = tf.square(tf.reduce_mean(self.create_loss(input, labels)))\n",
        "    return tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
        "\n",
        "  def train_unet(self):\n",
        "    ''' Handles training a UNET based off the data fed to it\n",
        "    '''\n",
        "\n",
        "\n",
        "    # This is where I would put my loss and optimization functions -..\n",
        "    # ..\n",
        "    # ..\n",
        "    # IF I HAD ONE!\n",
        "    #\n",
        "    # Meme Reference: https://www.youtube.com/watch?v=ciWPFvLS5IY\n",
        "    #\n",
        "    # On a serious note -.. Here is where we will plug in the deep regressor once that's built.\n",
        "    # After a UNET run the image will be passed to the deep regressor.\n",
        "    # The regressor will contain the loss function we are optimizing to.\n",
        "    input_ph = tf.placeholder(tf.float32, shape=[None, 256, 256, 1]) # Placeholder vals were given by paper in initial layer -- these numbers were referenced from the paper.\n",
        "    conv_input = self.generate_unet_arch(input_ph)\n",
        "    classifier = self.create_regressor(conv_input)\n",
        "    labels_placeholder = tf.placeholder(tf.float32, shape=self.labels_shape)\n",
        "    optimizer = self.create_optimizer(classifier, labels_placeholder)\n",
        "    loss = self.create_loss(classifier, labels_placeholder)\n",
        "    \n",
        "    unet_save = tf.train.Saver()\n",
        "      \n",
        "    with tf.Session() as session:\n",
        "      tf.global_variables_initializer().run()\n",
        "      for iteration in range(0, self.iterations): # counts for epochs -- or how many times we go through our data\n",
        "        for batch in range(0, self.batch_size):\n",
        "          y_b, X_b = self.data_class.get_next_batch()\n",
        "          #print(\"X shape: \", X_b)\n",
        "          #print(\"Y shape: \", y_b)\n",
        "          session.run(optimizer, feed_dict={input_ph:X_b, labels_placeholder:y_b})\n",
        "        if iteration % 10 == 0:\n",
        "          print(\"Iteration: \", iteration)\n",
        "          it_loss = session.run(loss, feed_dict={input_ph:X_b, labels_placeholder:y_b})\n",
        "          labels = session.run(classifier, feed_dict={input_ph: X_b})\n",
        "          print(self.save_graph(unet_save, session, \"output\"))\n",
        "          print(\"Predicted labels: \", labels)\n",
        "          print(\"Labels actual: \", y_b)\n",
        "          # Evaluate mse loss here and print the value\n",
        "          print(\"Passed 100 iterations with mse: \", it_loss)\n",
        "\n",
        "\n",
        "  def generalize_prediction(output):\n",
        "    ''' Handles generalizing UNET outputs to the labels so that we can better understand the predictions.\n",
        "        If the prediction is under 50% then we mark it as 0, otherwise keep the value.\n",
        "\n",
        "        Input: \n",
        "            - output - array of outputs based off labels from UNET\n",
        "\n",
        "        Return:\n",
        "            - return_prediction - array of normalized outputs from output input\n",
        "    '''\n",
        "    return_prediction = []\n",
        "    for prediction in output:\n",
        "      if(prediction > 0.5):\n",
        "        return_prediction.append(prediction)\n",
        "      else:\n",
        "        return_prediction.append(0)\n",
        "\n",
        "    return return_prediction\n",
        "\n",
        "  def test_unet(self, graph_out, input_x):\n",
        "    ''' Runs a trained UNET through an evaluation/test phase to detect errors\n",
        "\n",
        "        Parameters:\n",
        "          - graph_out: conv2d_tranpose tensor - The last layer in the graph\n",
        "          - input_x: image_arr  - Image array of shape [None, x, y, 1]\n",
        "\n",
        "        Returns:\n",
        "          - output: Returns the output of the unet graph\n",
        "    '''\n",
        "    with tf.Session() as session:\n",
        "      output = session.run(graph_out, feed_dict={input:input_x})\n",
        "\n",
        "    return output\n",
        "\n",
        "  def save_graph(self, unet_save, session, path):\n",
        "    ''' Saves a UNET graph\n",
        "        \n",
        "        Handles saving a UNET Graph to a specified path.\n",
        "        \n",
        "        Inputs:\n",
        "          - unet_save -- TF Saver instance\n",
        "          - session -- TF Session instance\n",
        "          - path -- path to save location\n",
        "        \n",
        "        Returns:\n",
        "          - String -- path to output unet\n",
        "          \n",
        "          \n",
        "        Save referenced from TensorFlow Documentation:\n",
        "        - https://www.tensorflow.org/guide/saved_model\n",
        "    '''\n",
        "    return unet_save.save(session, path)\n",
        "\n",
        "  def load_graph(self, unet_save, session, path):\n",
        "    ''' Loads a UNET graph\n",
        "    \n",
        "        Inputs:\n",
        "          - unet_save -- TF Saver instance\n",
        "          - session -- TF Session instance\n",
        "          - path -- path to save location\n",
        "        \n",
        "        Returns:\n",
        "          - None\n",
        "   \n",
        "        Load referenced from TensorFlow Documentation:\n",
        "        - https://www.tensorflow.org/guide/saved_model\n",
        "    '''\n",
        "    unet_save.restore(session, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcDoVC0wUgzQ",
        "colab_type": "code",
        "outputId": "adbd0bf8-50e4-4afe-d69b-27d278ca19d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_train   sample_data\t    test.zip   train.zip\n",
            "kaggle.json  sample_submission.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YWvL-RmfBBst",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def test_unet_training(image_path, csv_path, batch_size, iterations):\n",
        "  unet_data = UNET_DATA(label_classes=None, images_path=image_path, csv_path=csv_path)\n",
        "  unet = BSSCS_UNET(iterations, batch_size, unet_data, labels_shape=[None, 28])\n",
        "  print(unet_data.get_next_batch())\n",
        "  unet.train_unet()\n",
        "\n",
        "test_unet_training(image_path=\"data_train\", csv_path=\"train.csv\", batch_size=10, iterations=31)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BOvRtGHUezN_",
        "colab_type": "code",
        "outputId": "4c98151f-9a9f-474f-8e50-d3bb4c55a43d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir='/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.12.2 at http://a69bb1cc68f1:6006 (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}