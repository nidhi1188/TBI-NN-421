{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TBI-Group9-UNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3tpRHd5-41Cu",
        "colab_type": "code",
        "outputId": "ceacc083-ed52-4e41-a8cf-fd3218beec71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!pip install pillow\n",
        "import json\n",
        "import pandas as pd\n",
        "import tqdm as tqdm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm as tqdm\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1vupi9GeVq0H",
        "colab_type": "code",
        "outputId": "afba7d07-5daf-43d9-bfac-483a4e003f79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "cell_type": "code",
      "source": [
        "api_token = {\"username\":\"twoface262\",\"key\":\"453e89deca1ef616f15f5725eed93000\"}\n",
        "\n",
        "with open('kaggle.json', 'w') as kaggle_json:\n",
        "  json.dump(api_token, kaggle_json)\n",
        "  \n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Dataset source: https://www.kaggle.com/c/human-protein-atlas-image-classification\n",
        "# Attributes: Human Protein Atlas\n",
        "!kaggle competitions download -c human-protein-atlas-image-classification\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/446k [00:00<?, ?B/s]\n",
            "100% 446k/446k [00:00<00:00, 66.4MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/1.22M [00:00<?, ?B/s]\n",
            "100% 1.22M/1.22M [00:00<00:00, 82.7MB/s]\n",
            "Downloading test.zip to /content\n",
            "100% 4.35G/4.37G [00:47<00:00, 106MB/s]\n",
            "100% 4.37G/4.37G [00:47<00:00, 98.6MB/s]\n",
            "Downloading train.zip to /content\n",
            "100% 13.1G/13.1G [02:27<00:00, 129MB/s]\n",
            "100% 13.1G/13.1G [02:27<00:00, 95.4MB/s]\n",
            "data_train   sample_data\t    test.zip   train.zip\n",
            "kaggle.json  sample_submission.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x26mSbiN8CMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data_train\n",
        "!unzip train.zip -d data_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRayhjX2_fbJ",
        "colab_type": "code",
        "outputId": "9adf2ee1-3f39-4ee8-aabd-982c02369865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_train   sample_data\t    test.zip   train.zip\n",
            "kaggle.json  sample_submission.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LZtcBLmZ_eyk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Authors: Wezley Sherman\n",
        "#\n",
        "# Reference Attributes: Pydicom documentation, glob documentation\n",
        "# https://pydicom.github.io/pydicom/stable/getting_started.html\n",
        "# https://pymotw.com/2/glob/\n",
        "#\n",
        "# This class is a part of the BSSCS Net Framework to import DICOM images\n",
        "#\n",
        "# BSSCS Docs Importer location: BSSCS_DOCS/dicom.html\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "class UNET_DATA:\n",
        "\tdef __init__(self,label_classes, batch_size=10, labels_arr=None, image_arr=None, csv_path=None, images_path=None):\n",
        "\t\tself.current_batch = 0\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.total_batches = 10\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.labels = labels_arr\n",
        "\t\tself.images = image_arr\n",
        "\t\tself.label_classes = label_classes\n",
        "\n",
        "\t\tif csv_path and images_path:\n",
        "\t\t\tprint(\"Found CSV\")\n",
        "\t\t\tdata_frame = self.open_csv(csv_path)\n",
        "\t\t\tself.data_dictionary = self.fetch_images_with_csv(images_path, data_frame)\n",
        "\t\t\tself.data_keys = list(self.data_dictionary.keys())\n",
        "\t\telse:\n",
        "\t\t\tprint(\"No CSV\")\n",
        "\t\t\tself.data_dictionary = None\n",
        "\n",
        "\tdef set_batch_size(self, new_size):\n",
        "\t\t''' Responsible for setting a new batch size\n",
        "\n",
        "\t\t\tInput:\n",
        "\t\t\t\t- new_size: int -- corresponds to the new batch size we want to assign\n",
        "\t\t'''\n",
        "\t\tself.batch_size = new_size\n",
        "\n",
        "\tdef get_batch_size(self):\n",
        "\t\t''' Responsible for returning the batch size for the class\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t-int -- corresponds to the batch size\n",
        "\t\t'''\n",
        "\t\treturn self.batch_size\n",
        "\n",
        "\tdef get_total_batches(self):\n",
        "\t\t''' Responsible for returning how many batches of data are in our dataset\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- int -- corresponds to the number of batches in our dataset\n",
        "\t\t'''\n",
        "\t\treturn math.floor(self.images/batch_size)\n",
        "\n",
        "\t\n",
        "\tdef get_next_batch(self):\n",
        "\t\t'''\tResponsible for batching the data arrays and returning them\n",
        "\t\t\n",
        "\t\t\tReturns: \n",
        "\t\t\t\tlabel_batch: arr -- batch of labels for the associated image\n",
        "\t\t\t\timage_batch: arr -- batch of images for the associated labels\n",
        "\t\t'''\n",
        "\t\tstart_pos = (self.current_batch)\n",
        "\t\tend_pos =  (self.current_batch+1)\n",
        "\t\tprint(\"Called start\", start_pos)\n",
        "\t\tprint(\"end \", end_pos)\n",
        "\t\tlabel_batch = []\n",
        "\t\timage_batch = []\n",
        "\t\tif not self.data_dictionary:\n",
        "\t\t\tlabel_batch = self.labels[start_pos:end_pos]\n",
        "\t\t\timage_batch = self.images[start_pos:end_pos]\n",
        "\t\telse:\n",
        "\t\t\tlabel_batch_keys = self.data_keys[start_pos:end_pos]\n",
        "\t\t\tfor key in label_batch_keys:\n",
        "\t\t\t\tprint(\"keys \", key)        \n",
        "\t\t\t\timage_batch.append(np.resize(np.array(self.data_dictionary[key]['image_arr']), (256, 256, 1)))\n",
        "\t\t\t\tlabel_batch.append(self.data_dictionary[key]['labels'])\n",
        "\n",
        "\t\t# Reset the current batch once we've iterated through all of our data\n",
        "\t\tself.current_batch += 1\n",
        "\t\tif(self.current_batch >= self.batch_size):\n",
        "\t\t\tself.current_batch = 0\n",
        "\n",
        "\t\treturn label_batch, image_batch\n",
        "\t\t\n",
        "\tdef fetch_data(self, path_to_csv):\n",
        "\t\t''' Handles fetching the data from the DICOM Importer\n",
        "\t\t\n",
        "\t\t\tAssigns:\n",
        "\t\t\t\tself.labels\n",
        "\t\t\t\tself.images\n",
        "\t\t'''\n",
        "\t\timages_arr, labels_arr = self.import_labels_from_csv(path_to_csv)\n",
        "\t\tself.images = images_arr\n",
        "\t\tself.labels = labels_arr\n",
        "\t\t\n",
        "\tdef import_labels_from_csv(self, path):\n",
        "\t\t''' Handles opening a CSV of data and reading in the information to match\n",
        "\t\t\tThe image with the label.\n",
        "\t\t\t\n",
        "\t\t\tInput: \n",
        "\t\t\t\t- path: String -- path to the CSV\n",
        "\t\t\t\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- images: list -- list of image file names\n",
        "\t\t\t\t- labels: list -- list of boolean labels\n",
        "\t\t'''\n",
        "\t\tcsv_dataframe = pd.read_csv(path)\n",
        "\t\timages = list(csv_dataframe['file_name'])\n",
        "\t\tlabels = list(csv_dataframe['has_tbi'])\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef open_csv(self, path):\n",
        "\t\t''' Handles opening a labels CSV for the test set and returning the datframe\n",
        "\n",
        "\t\t\tInput:\n",
        "\t\t\t\t- path: String -- path to CSV\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- csv_dataframe: pandas dataframe for labels\n",
        "\n",
        "\t\t'''\n",
        "\t\tcsv_dataframe = pd.read_csv(path)\n",
        "\t\treturn csv_dataframe\n",
        "  \n",
        "\tdef scale_image(self, image, width, height):\n",
        "\t\t''' Handles scaling an image so that it can be fed into the UNET.\n",
        "\n",
        "\t\tInput:\n",
        "\t\t\t\t- image: A PIL Image instance\n",
        "\t\t\t\t- width: the new width we want the image to be\n",
        "\t\t\t\t- height: the new height we want the image to be\n",
        "\n",
        "\t\tReturns:\n",
        "\t\t\t\t- A PIL image instance that has been scaled\n",
        "\n",
        "\t\t\t\t* Will apply antialiasing to the \n",
        "\t\t'''\n",
        "\t\treturn image.resize((width, height), Image.ANTIALIAS)\n",
        "\n",
        "\n",
        "\tdef fetch_images_with_csv(self, path, dataframe):\n",
        "\t\t''' Handles fetching images from a filepath and constructs a dictionary with their labels\n",
        "\n",
        "\t\t\tInput:\n",
        "\t\t\t\t- path: String -- path to data folder\n",
        "\t\t\t\t- dataframe: pandas dataframe\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- Dictionary of data structured as:\n",
        "\t\t\t\t{\n",
        "\t\t\t\t\timage_name : {\n",
        "\t\t\t\t\t\timage_arr: [2D pixel array],\n",
        "\t\t\t\t\t\tlabels: [labels array]\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t'''\n",
        "\t\tdata_dictionary = {}\n",
        "\t\tcount = 0\n",
        "\t\tfor row in tqdm(dataframe.iterrows()):\n",
        "\t\t\tdata_dictionary[row[1][0]] = {}\n",
        "\t\t\timage_path = path +'/' + row[1][0] + '_blue.png'\n",
        "\t\t\timage = list(self.scale_image(Image.open(image_path), 256, 256).getdata())\n",
        "\t\t\tdata_dictionary[row[1][0]]['image_arr'] = image\n",
        "\t\t\tlabel_classes_arr = np.zeros(shape=(28))\n",
        "\t\t\tlabels_in_data = np.array(row[1][1].split(' '))\n",
        "\t\t\tprint(self.label_classes)\n",
        "\t\t\tprint(labels_in_data)\n",
        "\t\t\tfor label in labels_in_data:\n",
        "\t\t\t\tlabel_idx = int(label)\n",
        "\t\t\t\tprint(label_idx)\n",
        "\t\t\t\tprint(labels_in_data.size)\n",
        "\t\t\t\tlabel_classes_arr[label_idx] = 1\n",
        "\t\t\tprint(label_classes_arr)\n",
        "\t\t\tdata_dictionary[row[1][0]]['labels'] = label_classes_arr\n",
        "\t\t\tif count == self.batch_size:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tcount += 1\n",
        "\t\treturn data_dictionary\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTMEK-5D_VmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Authors: Wezley Sherman\n",
        "#\n",
        "# Reference Attributes: U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
        "# Authors: Olaf Ronneberger, Philipp Fischer, and Thomas Brox\n",
        "#\n",
        "# This class is a part of the BSSCS Net Framework to import DICOM images and batch them for the UNET\n",
        "#\n",
        "# BSSCS Docs Importer location: TBD\n",
        "#\n",
        "# Citation:\n",
        "# Ronneberger, et al. “U-Net: Convolutional Networks for Biomedical Image Segmentation.” \n",
        "#     [Astro-Ph/0005112] A Determination of the Hubble Constant from Cepheid Distances and a Model of the Local Peculiar Velocity Field, \n",
        "#     American Physical Society, 18 May 2015, arxiv.org/abs/1505.04597.\n",
        "# Site:\n",
        "# https://arxiv.org/pdf/1505.04597.pdf\n",
        "import tensorflow as tf\n",
        "\n",
        "class BSSCS_UNET:\n",
        "  def __init__(self, iterations, batch_size, data_class, labels_shape=[None, 1], learning_rate=0.0001):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.iterations = iterations\n",
        "    self.batch_size = batch_size\n",
        "    self.data_class = data_class\n",
        "    self.labels_shape = labels_shape\n",
        "\n",
        "\n",
        "  def generate_unet_arch(self, input):\n",
        "    ''' Handles generating a TF Implementation of a UNET utilizing the architecture discussed in\n",
        "    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\" by Ronneberger, Fischer, and Brox\n",
        "\n",
        "    The architecture for the UNET is not ours and all accrediation goes to Olaf Ronneberger, Philipp Fischer, and Thomas Brox. \n",
        "    We are not claiming any ownership for the architecture. \n",
        "    Implementing the UNET arch is comparable to implementing selection sort.\n",
        "\n",
        "    tf.layers.conv2d docs: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d\n",
        "    tf.layers.conv2d_transpost for up convolutions: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d_transpose\n",
        "    tf.concat for the copy and crop methods: https://www.tensorflow.org/api_docs/python/tf/concat\n",
        "    tf.slice for cropping the tensors: https://www.tensorflow.org/api_docs/python/tf/slice\n",
        "    Hopefully I implemented this correctly  ¯\\_(ツ)_/¯\n",
        "\n",
        "    Quick guide on cropping a tensor -..\n",
        "\n",
        "    So after some research through the doc's I found out that we can't just crop it as if it were an image, because we are dealing with Tensors (matricies of data).\n",
        "\n",
        "    In order to crop a tensor we must use TensorFlow's slice function (https://www.tensorflow.org/api_docs/python/tf/slice)\n",
        "\n",
        "    Here we are cropping the convolutional layer we are upsampling to be the size of the convolutional layer we are concating to. \n",
        "    I'm starting at the base coordinates for the tensor object, and am cropping JUST the images (or filters). Thus why we have [-1, size_x, size_y, -1]. \n",
        "    The '-1' values are there to ensure we are keeping the remaining elements of the dimension (AKA our batch size and number of filters) . \n",
        "    From TF Docs on the -1 values: \" If size[i] is -1, all remaining elements in dimension i are included in the slice. In other words, this is equivalent to setting: size[i] = input.dim_size(i) - begin[i]\"\n",
        "\n",
        "    Once the tensor is properly cropped (Where each filter is the same size as the tensor we are copying into), we can concat the tensors. \n",
        "    This allows us to copy in all of the previous filters into the current tensor. The final shape will be: [Batch, Img_X, Img_Y, [Filters_A + Filters_B]]\n",
        "    '''\n",
        "    # first block in UNET --> Concat with the final block\n",
        "    convolution_layer_1 = tf.layers.conv2d(inputs=input, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_2 = tf.layers.conv2d(inputs=convolution_layer_1, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_1 = tf.layers.max_pooling2d(inputs=convolution_layer_2, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # second block in UNET --> Concat with second to final block\n",
        "    convolution_layer_3 = tf.layers.conv2d(inputs=max_pooling_layer_1, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_4 = tf.layers.conv2d(inputs=convolution_layer_3, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_2 = tf.layers.max_pooling2d(inputs=convolution_layer_4, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # third block in UNET --> Concat with third from final block\n",
        "    convolution_layer_5 = tf.layers.conv2d(inputs=max_pooling_layer_2, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_6 = tf.layers.conv2d(inputs=convolution_layer_5, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_3 = tf.layers.max_pooling2d(inputs=convolution_layer_6, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # fourth block in UNET --> Concat with fourth from final block\n",
        "    convolution_layer_7 = tf.layers.conv2d(inputs=max_pooling_layer_3, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_8 = tf.layers.conv2d(inputs=convolution_layer_7, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    max_pooling_layer_4 = tf.layers.max_pooling2d(inputs=convolution_layer_8, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "    # middle UNET block\n",
        "    convolution_layer_9 = tf.layers.conv2d(inputs=max_pooling_layer_4, filters=1024, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_10 = tf.layers.conv2d(inputs=convolution_layer_9, filters=1024, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_1 = tf.layers.conv2d_transpose(inputs=convolution_layer_10, filters=1024, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "    # fourth from last \n",
        "    convolution_layer_8 = tf.slice(convolution_layer_8, [0, 0, 0, 0], [-1, convolution_up_1.shape[1], convolution_up_1.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_1, convolution_layer_8], axis=3) # Note: Experiment with the axis to ensure it is correct. Are we copying the batches or the filters? -- However; different axis's cause an error.\n",
        "    # print(concat_layer_1.shape) # Comes out to be [Batch_Size, Image_X, Image_Y, (Filters_Conv_8 + Filters_Conv_Up_1)]\n",
        "    convolution_layer_11 = tf.layers.conv2d(inputs=concat_layer_1, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_12 = tf.layers.conv2d(inputs=convolution_layer_11, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_2 = tf.layers.conv2d_transpose(inputs=convolution_layer_12, filters=512, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "\n",
        "    # third from last\n",
        "    convolution_layer_6 = tf.slice(convolution_layer_6, [0, 0, 0, 0], [-1, convolution_up_2.shape[1], convolution_up_2.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_2, convolution_layer_6], axis=3)\n",
        "    convolution_layer_13 = tf.layers.conv2d(inputs=convolution_up_2, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_14 = tf.layers.conv2d(inputs=convolution_layer_13, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_3 = tf.layers.conv2d_transpose(inputs=convolution_layer_14, filters=256, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "    # second from last\n",
        "    convolution_layer_4 = tf.slice(convolution_layer_4, [0, 0, 0, 0], [-1, convolution_up_3.shape[1], convolution_up_3.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_3, convolution_layer_4], axis=3)\n",
        "    convolution_layer_15 = tf.layers.conv2d(inputs=convolution_up_3, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_16 = tf.layers.conv2d(inputs=convolution_layer_15, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_4 = tf.layers.conv2d_transpose(inputs=convolution_layer_16, filters=128, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "    # last block\n",
        "    convolution_layer_2 = tf.slice(convolution_layer_2, [0, 0, 0, 0], [-1, convolution_up_4.shape[1], convolution_up_4.shape[2], -1])\n",
        "    concat_layer_1 = tf.concat([convolution_up_4, convolution_layer_2], axis=3)\n",
        "    convolution_layer_17 = tf.layers.conv2d(inputs=convolution_up_4, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_18 = tf.layers.conv2d(inputs=convolution_layer_17, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_layer_19 = tf.layers.conv2d(inputs=convolution_layer_18, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "    convolution_up_5 = tf.layers.conv2d_transpose(inputs=convolution_layer_19, filters=2, kernel_size=[1, 1], strides=1, padding=\"SAME\")\n",
        "    print(convolution_up_5.shape)\n",
        "    flattened = tf.reshape(convolution_up_5, [-1, 504])\n",
        "    return flattened\n",
        "\n",
        "  def create_regressor(self, input): \n",
        "    ''' Handles creating the regressor for the UNET classification\n",
        "\n",
        "        Parameters:\n",
        "          - input -- input layer (flattened layer from UNET) \n",
        "        Returns:\n",
        "          - Tensor -- last layer in the regressor\n",
        "    '''\n",
        "    reg_input = tf.layers.dense(inputs=input, units=504, activation=tf.nn.relu)\n",
        "    reg_hidden = tf.layers.dense(inputs=reg_input, units=8000, activation=tf.nn.relu)\n",
        "    reg_hidden1 = tf.layers.dense(inputs=reg_hidden, units=10500, activation=tf.nn.relu)\n",
        "    reg_hidden2 = tf.layers.dense(inputs=reg_hidden1, units=15500, activation=tf.nn.relu)\n",
        "    reg_out = tf.layers.dense(inputs=reg_hidden2, units=28)\n",
        "    return reg_out\n",
        "\n",
        "  def create_loss(self, input, labels):\n",
        "    ''' Handles creating a loss function and returning it to the optimizer\n",
        "\n",
        "      Parameters:\n",
        "        - Input: The final layer in the graph we are computing the loss for\n",
        "        - Labels: The labels for the batch we are computing the loss for\n",
        "\n",
        "      Returns:\n",
        "        - Defined loss function\n",
        "\n",
        "      TensorFlow documentation: \n",
        "      https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2\n",
        "    '''\n",
        "    return tf.nn.softmax_cross_entropy_with_logits_v2(logits=input, labels=labels)\n",
        "\n",
        "  def create_optimizer(self, input, labels):\n",
        "    '''\n",
        "\n",
        "      TensorFlow documentation: \n",
        "      https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n",
        "    '''\n",
        "    loss = tf.reduce_mean(self.create_loss(input, labels))\n",
        "    return tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
        "\n",
        "  def train_unet(self):\n",
        "    ''' Handles training a UNET based off the data fed to it\n",
        "    '''\n",
        "\n",
        "\n",
        "    # This is where I would put my loss and optimization functions -..\n",
        "    # ..\n",
        "    # ..\n",
        "    # IF I HAD ONE!\n",
        "    #\n",
        "    # Meme Reference: https://www.youtube.com/watch?v=ciWPFvLS5IY\n",
        "    #\n",
        "    # On a serious note -.. Here is where we will plug in the deep regressor once that's built.\n",
        "    # After a UNET run the image will be passed to the deep regressor.\n",
        "    # The regressor will contain the loss function we are optimizing to.\n",
        "    input_ph = tf.placeholder(tf.float32, shape=[None, 256, 256, 1]) # Placeholder vals were given by paper in initial layer -- these numbers were referenced from the paper.\n",
        "    conv_input = self.generate_unet_arch(input_ph)\n",
        "    classifier = self.create_regressor(conv_input)\n",
        "    labels_placeholder = tf.placeholder(tf.float32, shape=self.labels_shape)\n",
        "    optimizer = self.create_optimizer(classifier, labels_placeholder)\n",
        "    loss = self.create_loss(classifier, labels_placeholder)\n",
        "    \n",
        "    unet_save = tf.train.Saver()\n",
        "      \n",
        "    with tf.Session() as session:\n",
        "      tf.global_variables_initializer().run()\n",
        "      for iteration in range(0, self.iterations): # counts for epochs -- or how many times we go through our data\n",
        "        for batch in range(0, self.batch_size):\n",
        "          y_b, X_b = self.data_class.get_next_batch()\n",
        "          #print(\"X shape: \", X_b)\n",
        "          #print(\"Y shape: \", y_b)\n",
        "          session.run(optimizer, feed_dict={input_ph:X_b, labels_placeholder:y_b})\n",
        "        if iteration % 10 == 0:\n",
        "          print(\"Iteration: \", iteration)\n",
        "          it_loss = session.run(loss, feed_dict={input_ph:X_b, labels_placeholder:y_b})\n",
        "          labels = session.run(classifier, feed_dict={input_ph: X_b})\n",
        "          print(self.save_graph(unet_save, session, \"output\"))\n",
        "          print(\"Predicted labels: \", labels)\n",
        "          print(\"Labels actual: \", y_b)\n",
        "          # Evaluate mse loss here and print the value\n",
        "          print(\"Passed 100 iterations with mse: \", it_loss)\n",
        "\n",
        "\n",
        "  def generalize_prediction(output):\n",
        "    ''' Handles generalizing UNET outputs to the labels so that we can better understand the predictions.\n",
        "        If the prediction is under 50% then we mark it as 0, otherwise keep the value.\n",
        "\n",
        "        Input: \n",
        "            - output - array of outputs based off labels from UNET\n",
        "\n",
        "        Return:\n",
        "            - return_prediction - array of normalized outputs from output input\n",
        "    '''\n",
        "    return_prediction = []\n",
        "    for prediction in output:\n",
        "      if(prediction > 0.5):\n",
        "        return_prediction.append(prediction)\n",
        "      else:\n",
        "        return_prediction.append(0)\n",
        "\n",
        "    return return_prediction\n",
        "\n",
        "  def test_unet(self, graph_out, input_x):\n",
        "    ''' Runs a trained UNET through an evaluation/test phase to detect errors\n",
        "\n",
        "        Parameters:\n",
        "          - graph_out: conv2d_tranpose tensor - The last layer in the graph\n",
        "          - input_x: image_arr  - Image array of shape [None, x, y, 1]\n",
        "\n",
        "        Returns:\n",
        "          - output: Returns the output of the unet graph\n",
        "    '''\n",
        "    with tf.Session() as session:\n",
        "      output = session.run(graph_out, feed_dict={input:input_x})\n",
        "\n",
        "    return output\n",
        "\n",
        "  def save_graph(self, unet_save, session, path):\n",
        "    ''' Saves a UNET graph\n",
        "        \n",
        "        Handles saving a UNET Graph to a specified path.\n",
        "        \n",
        "        Inputs:\n",
        "          - unet_save -- TF Saver instance\n",
        "          - session -- TF Session instance\n",
        "          - path -- path to save location\n",
        "        \n",
        "        Returns:\n",
        "          - String -- path to output unet\n",
        "          \n",
        "          \n",
        "        Save referenced from TensorFlow Documentation:\n",
        "        - https://www.tensorflow.org/guide/saved_model\n",
        "    '''\n",
        "    return unet_save.save(session, path)\n",
        "\n",
        "  def load_graph(self, unet_save, session, path):\n",
        "    ''' Loads a UNET graph\n",
        "    \n",
        "        Inputs:\n",
        "          - unet_save -- TF Saver instance\n",
        "          - session -- TF Session instance\n",
        "          - path -- path to save location\n",
        "        \n",
        "        Returns:\n",
        "          - None\n",
        "   \n",
        "        Load referenced from TensorFlow Documentation:\n",
        "        - https://www.tensorflow.org/guide/saved_model\n",
        "    '''\n",
        "    unet_save.restore(session, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcDoVC0wUgzQ",
        "colab_type": "code",
        "outputId": "54dfb7d0-6f67-423f-9ee6-45f8fc61db3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_train  kaggle.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YWvL-RmfBBst",
        "colab_type": "code",
        "outputId": "ca2c56a4-4e1d-40c9-8532-a7bb53b04aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2295
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def test_unet_training(image_path, csv_path, batch_size, iterations):\n",
        "  unet_data = UNET_DATA(label_classes=None, images_path=image_path, csv_path=csv_path)\n",
        "  unet = BSSCS_UNET(iterations, batch_size, unet_data, labels_shape=[None, 28])\n",
        "  print(unet_data.get_next_batch())\n",
        "  unet.train_unet()\n",
        "\n",
        "test_unet_training(image_path=\"data_train\", csv_path=\"train.csv\", batch_size=10, iterations=11)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9it [00:00, 89.01it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found CSV\n",
            "None\n",
            "['16' '0']\n",
            "16\n",
            "2\n",
            "0\n",
            "2\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['7' '1' '2' '0']\n",
            "7\n",
            "4\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "0\n",
            "4\n",
            "[1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['5']\n",
            "5\n",
            "1\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['1']\n",
            "1\n",
            "1\n",
            "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['18']\n",
            "18\n",
            "1\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['0']\n",
            "0\n",
            "1\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['25' '2']\n",
            "25\n",
            "2\n",
            "2\n",
            "2\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 0.]\n",
            "None\n",
            "['0']\n",
            "0\n",
            "1\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['2' '0']\n",
            "2\n",
            "2\n",
            "0\n",
            "2\n",
            "[1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['7']\n",
            "7\n",
            "1\n",
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0.]\n",
            "None\n",
            "['23']\n",
            "23\n",
            "1\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0.]\n",
            "Called start 0\n",
            "end  1\n",
            "keys  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0\n",
            "([array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])], [array([[[ 4],\n",
            "        [12],\n",
            "        [11],\n",
            "        ...,\n",
            "        [10],\n",
            "        [10],\n",
            "        [ 0]],\n",
            "\n",
            "       [[12],\n",
            "        [ 8],\n",
            "        [ 8],\n",
            "        ...,\n",
            "        [11],\n",
            "        [ 2],\n",
            "        [ 0]],\n",
            "\n",
            "       [[11],\n",
            "        [ 4],\n",
            "        [ 8],\n",
            "        ...,\n",
            "        [ 6],\n",
            "        [ 1],\n",
            "        [ 0]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[ 0],\n",
            "        [ 0],\n",
            "        [ 0],\n",
            "        ...,\n",
            "        [ 0],\n",
            "        [ 0],\n",
            "        [ 0]],\n",
            "\n",
            "       [[ 3],\n",
            "        [ 0],\n",
            "        [ 1],\n",
            "        ...,\n",
            "        [ 0],\n",
            "        [ 0],\n",
            "        [ 0]],\n",
            "\n",
            "       [[ 4],\n",
            "        [ 2],\n",
            "        [ 3],\n",
            "        ...,\n",
            "        [ 0],\n",
            "        [ 0],\n",
            "        [ 0]]])])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(?, 252, 252, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BOvRtGHUezN_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir='/'"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}