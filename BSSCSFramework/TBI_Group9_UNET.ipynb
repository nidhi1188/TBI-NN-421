{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TBI-Group9-UNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "3tpRHd5-41Cu",
        "colab_type": "code",
        "outputId": "362e131f-12fd-4382-822d-d146c2719580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "api_token = {\"username\":\"twoface262\",\"key\":\"453e89deca1ef616f15f5725eed93000\"}\n",
        "\n",
        "with open('kaggle.json', 'w') as kaggle_json:\n",
        "  json.dump(api_token, kaggle_json)\n",
        "  \n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c human-protein-atlas-image-classification\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.2)\n",
            "Requirement already satisfied: urllib3<1.23.0,>=1.15 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.22)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2018.11.29)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.0.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: Unidecode>=0.04.16 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.0.23)\n",
            "Downloading sample_submission.csv to /content\n",
            "  0% 0.00/446k [00:00<?, ?B/s]\n",
            "100% 446k/446k [00:00<00:00, 67.8MB/s]\n",
            "Downloading train.csv to /content\n",
            "  0% 0.00/1.22M [00:00<?, ?B/s]\n",
            "100% 1.22M/1.22M [00:00<00:00, 82.1MB/s]\n",
            "Downloading test.zip to /content\n",
            "100% 4.37G/4.37G [01:53<00:00, 8.18MB/s]\n",
            "\n",
            "Downloading train.zip to /content\n",
            "100% 13.1G/13.1G [07:45<00:00, 23.6MB/s]\n",
            "\n",
            "kaggle.json  sample_data  sample_submission.csv  test.zip  train.csv  train.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x26mSbiN8CMs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir data_train\n",
        "!unzip train.zip -d data_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GRayhjX2_fbJ",
        "colab_type": "code",
        "outputId": "c52cc066-6934-46a2-942d-06eb2455c1ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data_train   sample_data\t    test.zip  train.csv\n",
            "kaggle.json  sample_submission.csv  train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LZtcBLmZ_eyk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class UNET_DATA:\n",
        "\tdef __init__(self, labels_arr=None, image_arr=None):\n",
        "\t\tself.current_batch = 0\n",
        "\t\tself.batch_size = 0\n",
        "\t\tself.total_batches = 0\n",
        "\t\tself.labels = labels_arr\n",
        "\t\tself.images = image_arr\n",
        "\n",
        "\t\tif csv_path and images_path:\n",
        "\t\t\tprint(\"Found CSV\")\n",
        "\t\t\tdata_frame = self.open_csv(csv_path)\n",
        "\t\t\tself.data_dictionary = self.fetch_images_with_csv(images_path, data_frame)\n",
        "\t\t\tself.data_keys = list(self.data_dictionary.keys())\n",
        "\t\telse:\n",
        "\t\t\tprint(\"No CSV\")\n",
        "\t\t\tself.data_dictionary = None\n",
        "\n",
        "\tdef set_batch_size(self, new_size):\n",
        "\t\t''' Responsible for setting a new batch size\n",
        "\n",
        "\t\t\tInput:\n",
        "\t\t\t\t- new_size: int -- corresponds to the new batch size we want to assign\n",
        "\t\t'''\n",
        "\t\tself.batch_size = new_size\n",
        "\n",
        "\tdef get_batch_size(self):\n",
        "\t\t''' Responsible for returning the batch size for the class\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t-int -- corresponds to the batch size\n",
        "\t\t'''\n",
        "\t\treturn self.batch_size\n",
        "\n",
        "\tdef get_total_batches(self):\n",
        "\t\t''' Responsible for returning how many batches of data are in our dataset\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- int -- corresponds to the number of batches in our dataset\n",
        "\t\t'''\n",
        "\t\treturn math.floor(self.images/batch_size)\n",
        "\n",
        "\t\n",
        "\tdef get_next_batch(self):\n",
        "\t\t'''\tResponsible for batching the data arrays and returning them\n",
        "\t\t\n",
        "\t\t\tReturns: \n",
        "\t\t\t\tlabel_batch: arr -- batch of labels for the associated image\n",
        "\t\t\t\timage_batch: arr -- batch of images for the associated labels\n",
        "\t\t'''\n",
        "\t\tstart_pos = (self.batch_size * self.current_batch)\n",
        "\t\tend_pos =  (self.batch_size * self.current_batch+1)\n",
        "\n",
        "\t\tlabel_batch = []\n",
        "\t\timage_batch = []\n",
        "\t\tif not self.data_dictionary:\n",
        "\t\t\tlabel_batch = self.labels[start_pos:end_pos]\n",
        "\t\t\timage_batch = self.images[start_pos:end_pos]\n",
        "\t\telse:\n",
        "\t\t\tlabel_batch_keys = self.data_keys[start_pos:end_pos]\n",
        "\t\t\tfor key in label_batch_keys:\n",
        "\t\t\t\timage_batch.append(np.resize(np.array(self.data_dictionary[key]['image_arr']), (512, 512, 1)))\n",
        "\t\t\t\tlabel_batch.append(self.data_dictionary[key]['labels'])\n",
        "\n",
        "\t\t# Reset the current batch once we've iterated through all of our data\n",
        "\t\tself.current_batch += 1\n",
        "\t\tif(self.current_batch >= self.total_batches):\n",
        "\t\t\tself.current_batch = 0\n",
        "\n",
        "\t\treturn label_batch, image_batch\n",
        "\t\t\n",
        "\tdef fetch_data(self, path_to_csv):\n",
        "\t\t''' Handles fetching the data from the DICOM Importer\n",
        "\t\t\n",
        "\t\t\tAssigns:\n",
        "\t\t\t\tself.labels\n",
        "\t\t\t\tself.images\n",
        "\t\t'''\n",
        "\t\timages_arr, labels_arr = self.import_labels_from_csv(path_to_csv)\n",
        "\t\tself.images = images_arr\n",
        "\t\tself.labels = labels_arr\n",
        "\t\t\n",
        "\tdef import_labels_from_csv(self, path):\n",
        "\t\t''' Handles opening a CSV of data and reading in the information to match\n",
        "\t\t\tThe image with the label.\n",
        "\t\t\t\n",
        "\t\t\tInput: \n",
        "\t\t\t\t- path: String -- path to the CSV\n",
        "\t\t\t\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- images: list -- list of image file names\n",
        "\t\t\t\t- labels: list -- list of boolean labels\n",
        "\t\t'''\n",
        "\t\tcsv_dataframe = pd.read_csv(path)\n",
        "\t\timages = list(csv_dataframe['file_name'])\n",
        "\t\tlabels = list(csv_dataframe['has_tbi'])\n",
        "\t\treturn images, labels\n",
        "\n",
        "\tdef open_csv(self, path):\n",
        "\t\t''' Handles opening a labels CSV for the test set and returning the datframe\n",
        "\n",
        "\t\t\tInput:\n",
        "\t\t\t\t- path: String -- path to CSV\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- csv_dataframe: pandas dataframe for labels\n",
        "\n",
        "\t\t'''\n",
        "\t\tcsv_dataframe = pd.read_csv(path)\n",
        "\t\treturn csv_dataframe\n",
        "\n",
        "\tdef fetch_images_with_csv(self, path, dataframe):\n",
        "\t\t''' Handles fetching images from a filepath and constructs a dictionary with their labels\n",
        "\n",
        "\t\t\tInput:\n",
        "\t\t\t\t- path: String -- path to data folder\n",
        "\t\t\t\t- dataframe: pandas dataframe\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- Dictionary of data structured as:\n",
        "\t\t\t\t{\n",
        "\t\t\t\t\timage_name : {\n",
        "\t\t\t\t\t\timage_arr: [2D pixel array],\n",
        "\t\t\t\t\t\tlabels: [labels array]\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t}\n",
        "\t\t'''\n",
        "\t\tdata_dictionary = {}\n",
        "\t\tcount = 0\n",
        "\t\tfor row in tqdm(dataframe.iterrows()):\n",
        "\t\t\tdata_dictionary[row[1][0]] = {}\n",
        "\t\t\timage_path = path +'/' + row[1][0] + '_blue.png'\n",
        "\t\t\timage = list(Image.open(image_path).getdata())\n",
        "\t\t\tdata_dictionary[row[1][0]]['image_arr'] = image\n",
        "\t\t\tdata_dictionary[row[1][0]]['labels'] = np.resize(np.array(row[1][1].split(' ')[0]), (1))\n",
        "\t\t\tif count == 1:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tcount += 1\n",
        "\t\treturn data_dictionary\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fTMEK-5D_VmR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "class BSSCS_UNET:\n",
        "\tdef __init__(self, iterations, batch_size, data_class, labels_shape=[None, 1], learning_rate=0.001):\n",
        "\t\tself.learning_rate = learning_rate\n",
        "\t\tself.iterations = iterations\n",
        "\t\tself.batch_size = batch_size\n",
        "\t\tself.data_class = data_class\n",
        "\t\tself.labels_shape = labels_shape\n",
        "\n",
        "\n",
        "\tdef generate_unet_arch(self, input):\n",
        "\t\t''' Handles generating a TF Implementation of a UNET utilizing the architecture discussed in\n",
        "\t\t    \"U-Net: Convolutional Networks for Biomedical Image Segmentation\" by Ronneberger, Fischer, and Brox\n",
        "\n",
        "\t\t    The architecture for the UNET is not ours and all accrediation goes to Olaf Ronneberger, Philipp Fischer, and Thomas Brox. \n",
        "\t\t    We are not claiming any ownership for the architecture. \n",
        "\t\t    Implementing the UNET arch is comparable to implementing selection sort.\n",
        "\n",
        "\t\t    tf.layers.conv2d docs: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d\n",
        "\t\t\ttf.layers.conv2d_transpost for up convolutions: https://www.tensorflow.org/api_docs/python/tf/layers/conv2d_transpose\n",
        "\t\t\ttf.concat for the copy and crop methods: https://www.tensorflow.org/api_docs/python/tf/concat\n",
        "\t\t\ttf.slice for cropping the tensors: https://www.tensorflow.org/api_docs/python/tf/slice\n",
        "\t\t\tHopefully I implemented this correctly  ¯\\_(ツ)_/¯\n",
        "\n",
        "\t\t\tQuick guide on cropping a tensor -..\n",
        "\n",
        "\t\t\tSo after some research through the doc's I found out that we can't just crop it as if it were an image, because we are dealing with Tensors (matricies of data).\n",
        "\n",
        "\t\t\tIn order to crop a tensor we must use TensorFlow's slice function (https://www.tensorflow.org/api_docs/python/tf/slice)\n",
        "\t\t\t\n",
        "\t\t\tHere we are cropping the convolutional layer we are upsampling to be the size of the convolutional layer we are concating to. \n",
        "\t\t\tI'm starting at the base coordinates for the tensor object, and am cropping JUST the images (or filters). Thus why we have [-1, size_x, size_y, -1]. \n",
        "\t\t\tThe '-1' values are there to ensure we are keeping the remaining elements of the dimension (AKA our batch size and number of filters) . \n",
        "\t\t\tFrom TF Docs on the -1 values: \" If size[i] is -1, all remaining elements in dimension i are included in the slice. In other words, this is equivalent to setting: size[i] = input.dim_size(i) - begin[i]\"\n",
        "\n",
        "\t\t\tOnce the tensor is properly cropped (Where each filter is the same size as the tensor we are copying into), we can concat the tensors. \n",
        "\t\t\tThis allows us to copy in all of the previous filters into the current tensor. The final shape will be: [Batch, Img_X, Img_Y, [Filters_A + Filters_B]]\n",
        "\t\t'''\n",
        "\t\t# first block in UNET --> Concat with the final block\n",
        "\t\tconvolution_layer_1 = tf.layers.conv2d(inputs=input, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_2 = tf.layers.conv2d(inputs=convolution_layer_1, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tmax_pooling_layer_1 = tf.layers.max_pooling2d(inputs=convolution_layer_2, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "\t\t# second block in UNET --> Concat with second to final block\n",
        "\t\tconvolution_layer_3 = tf.layers.conv2d(inputs=max_pooling_layer_1, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_4 = tf.layers.conv2d(inputs=convolution_layer_3, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tmax_pooling_layer_2 = tf.layers.max_pooling2d(inputs=convolution_layer_4, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "\t\t# third block in UNET --> Concat with third from final block\n",
        "\t\tconvolution_layer_5 = tf.layers.conv2d(inputs=max_pooling_layer_2, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_6 = tf.layers.conv2d(inputs=convolution_layer_5, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tmax_pooling_layer_3 = tf.layers.max_pooling2d(inputs=convolution_layer_6, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "\t\t# fourth block in UNET --> Concat with fourth from final block\n",
        "\t\tconvolution_layer_7 = tf.layers.conv2d(inputs=max_pooling_layer_3, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_8 = tf.layers.conv2d(inputs=convolution_layer_7, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tmax_pooling_layer_4 = tf.layers.max_pooling2d(inputs=convolution_layer_8, pool_size=[2, 2], strides=1, padding=\"VALID\")\n",
        "\n",
        "\t\t# middle UNET block\n",
        "\t\tconvolution_layer_9 = tf.layers.conv2d(inputs=max_pooling_layer_4, filters=1024, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_10 = tf.layers.conv2d(inputs=convolution_layer_9, filters=1024, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_up_1 = tf.layers.conv2d_transpose(inputs=convolution_layer_10, filters=1024, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\t\t\n",
        "\t\t# fourth from last \n",
        "\t\tconvolution_layer_8 = tf.slice(convolution_layer_8, [0, 0, 0, 0], [-1, convolution_up_1.shape[1], convolution_up_1.shape[2], -1])\n",
        "\t\tconcat_layer_1 = tf.concat([convolution_up_1, convolution_layer_8], axis=3) # Note: Experiment with the axis to ensure it is correct. Are we copying the batches or the filters? -- However; different axis's cause an error.\n",
        "\t\t# print(concat_layer_1.shape) # Comes out to be [Batch_Size, Image_X, Image_Y, (Filters_Conv_8 + Filters_Conv_Up_1)]\n",
        "\t\tconvolution_layer_11 = tf.layers.conv2d(inputs=concat_layer_1, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_12 = tf.layers.conv2d(inputs=convolution_layer_11, filters=512, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_up_2 = tf.layers.conv2d_transpose(inputs=convolution_layer_12, filters=512, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "\t\t\n",
        "\t\t# third from last\n",
        "\t\tconvolution_layer_6 = tf.slice(convolution_layer_6, [0, 0, 0, 0], [-1, convolution_up_2.shape[1], convolution_up_2.shape[2], -1])\n",
        "\t\tconcat_layer_1 = tf.concat([convolution_up_2, convolution_layer_6], axis=3)\n",
        "\t\tconvolution_layer_13 = tf.layers.conv2d(inputs=convolution_up_2, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_14 = tf.layers.conv2d(inputs=convolution_layer_13, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_up_3 = tf.layers.conv2d_transpose(inputs=convolution_layer_14, filters=256, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "\t\t# second from last\n",
        "\t\tconvolution_layer_4 = tf.slice(convolution_layer_4, [0, 0, 0, 0], [-1, convolution_up_3.shape[1], convolution_up_3.shape[2], -1])\n",
        "\t\tconcat_layer_1 = tf.concat([convolution_up_3, convolution_layer_4], axis=3)\n",
        "\t\tconvolution_layer_15 = tf.layers.conv2d(inputs=convolution_up_3, filters=256, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_16 = tf.layers.conv2d(inputs=convolution_layer_15, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_up_4 = tf.layers.conv2d_transpose(inputs=convolution_layer_16, filters=128, kernel_size=[2, 2], strides=1, padding=\"SAME\")\n",
        "\n",
        "\t\t# last block\n",
        "\t\tconvolution_layer_2 = tf.slice(convolution_layer_2, [0, 0, 0, 0], [-1, convolution_up_4.shape[1], convolution_up_4.shape[2], -1])\n",
        "\t\tconcat_layer_1 = tf.concat([convolution_up_4, convolution_layer_2], axis=3)\n",
        "\t\tconvolution_layer_17 = tf.layers.conv2d(inputs=convolution_up_4, filters=128, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_18 = tf.layers.conv2d(inputs=convolution_layer_17, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_layer_19 = tf.layers.conv2d(inputs=convolution_layer_18, filters=64, kernel_size=[3, 3], strides=1, padding=\"SAME\", activation=tf.nn.relu)\n",
        "\t\tconvolution_up_5 = tf.layers.conv2d_transpose(inputs=convolution_layer_19, filters=2, kernel_size=[1, 1], strides=1, padding=\"SAME\")\n",
        "\t\t\n",
        "\t\tflattened = tf.reshape(convolution_up_5, [-1, 1016])\n",
        "\t\treturn flattened\n",
        "\n",
        "\tdef create_regressor(self, input): \n",
        "\t\t''' Handles creating the regressor for the UNET classification\n",
        "\n",
        "\t\t\tParameters:\n",
        "\t\t\t\t- input -- input layer (flattened layer from UNET) \n",
        "\t\t\tReturns:\n",
        "\t\t\t \t- Tensor -- last layer in the regressor\n",
        "\t\t'''\n",
        "\t\treg_input = tf.layers.dense(inputs=input, units=1016, activation=tf.nn.relu)\n",
        "\t\t#reg_hidden = tf.layers.dense(inputs=reg_input, units=20, activation=tf.nn.relu)\n",
        "\t\treg_out = tf.layers.dense(inputs=reg_input, units=2)\n",
        "\t\treturn reg_out\n",
        "\n",
        "\tdef create_loss(self, input, labels):\n",
        "\t\t''' Handles creating a loss function and returning it to the optimizer\n",
        "\n",
        "\t\t\tParameters:\n",
        "\t\t\t \t- Input: The final layer in the graph we are computing the loss for\n",
        "\t\t\t \t- Labels: The labels for the batch we are computing the loss for\n",
        "\n",
        "\t\t\t Returns:\n",
        "\t\t\t \t- Defined loss function\n",
        "\n",
        "\t\t\tTensorFlow documentation: \n",
        "\t\t\thttps://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits_v2\n",
        "\t\t'''\n",
        "\t\treturn tf.nn.softmax_cross_entropy_with_logits_v2(logits=input, labels=labels)\n",
        "\n",
        "\tdef create_optimizer(self, input, labels):\n",
        "\t\t'''\n",
        "\n",
        "\t\t\tTensorFlow documentation: \n",
        "\t\t\thttps://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer\n",
        "\t\t'''\n",
        "\t\tloss = tf.reduce_mean(self.create_loss(input, labels))\n",
        "\t\treturn tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(loss)\n",
        "\n",
        "\tdef train_unet(self):\n",
        "\t\t''' Handles training a UNET based off the data fed to it\n",
        "\t\t'''\n",
        "\n",
        "\n",
        "\t\t# This is where I would put my loss and optimization functions -..\n",
        "\t\t# ..\n",
        "\t\t# ..\n",
        "\t\t# IF I HAD ONE!\n",
        "\t\t#\n",
        "\t\t# Meme Reference: https://www.youtube.com/watch?v=ciWPFvLS5IY\n",
        "\t\t#\n",
        "\t\t# On a serious note -.. Here is where we will plug in the deep regressor once that's built.\n",
        "\t\t# After a UNET run the image will be passed to the deep regressor.\n",
        "\t\t# The regressor will contain the loss function we are optimizing to.\n",
        "\t\tinput_ph = tf.placeholder(tf.float32, shape=[None, 512, 512, 1]) # Placeholder vals were given by paper in initial layer -- these numbers were referenced from the paper.\n",
        "\t\tconv_input = self.generate_unet_arch(input_ph)\n",
        "\t\tclassifier = self.create_regressor(conv_input)\n",
        "\t\tlabels_placeholder = tf.placeholder(tf.float32, shape=self.labels_shape)\n",
        "\t\toptimizer = self.create_optimizer(classifier, labels_placeholder)\n",
        "\t\tloss = self.create_loss(classifier, labels_placeholder)\n",
        "\t\twith tf.Session() as session:\n",
        "\t\t\ttf.global_variables_initializer().run()\n",
        "\t\t\tfor iteration in range(0, self.iterations): # counts for epochs -- or how many times we go through our data\n",
        "\t\t\t\tfor batch in range(0, self.batch_size):\n",
        "\t\t\t\t\ty_b, X_b = self.data_class.get_next_batch()\n",
        "\t\t\t\t\tsession.run(optimizer, feed_dict={input_ph:X_b, labels_placeholder:y_b})\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tif iteration % 500 == 0:\n",
        "\t\t\t\t\tit_loss = session.run(loss, feed_dict={input_ph:X_b, labels_placeholder:y_b})\n",
        "\n",
        "\t\t\t\t\t# Evaluate mse loss here and print the value\n",
        "\t\t\t\t\tprint(\"Passed 500 iterations with mse: \" + it_loss)\n",
        "\t\t\n",
        "\n",
        "\tdef test_unet(self, graph_out, input_x):\n",
        "\t\t''' Runs a trained UNET through an evaluation/test phase to detect errors\n",
        "\n",
        "\t\t\tParameters:\n",
        "\t\t\t\t- graph_out: conv2d_tranpose tensor - The last layer in the graph\n",
        "\t\t\t\t- input_x: image_arr  - Image array of shape [None, x, y, 1]\n",
        "\n",
        "\t\t\tReturns:\n",
        "\t\t\t\t- output: Returns the output of the unet graph\n",
        "\t\t'''\n",
        "\t\twith tf.Session() as session:\n",
        "\t\t\toutput = session.run(graph_out, feed_dict={input:input_x})\n",
        "\n",
        "\t\treturn output\n",
        "\n",
        "\tdef save_graph(self):\n",
        "\t\t''' Saves a UNET graph\n",
        "\t\t'''\n",
        "\t\t# To-Do: Implement when deep regressor is finished\n",
        "\t\treturn None\n",
        "\n",
        "\tdef load_graph(self):\n",
        "\t\t''' Loads a UNET graph\n",
        "\t\t'''\n",
        "\t\t# To-Do: Implement when deep regressor is finished\n",
        "\t\treturn None"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}